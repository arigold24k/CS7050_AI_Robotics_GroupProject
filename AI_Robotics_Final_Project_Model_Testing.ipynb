{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e633fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "\n",
    "clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a54c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "%reload_ext tensorboard\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Data containers\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Data Manipulation and Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Hugging face dataset loading\n",
    "# from datasets import load_dataset\n",
    "# from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eab45793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Deep_Learning\n",
    "# import tensorflow_datasets as tfds\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Activation, Bidirectional, Conv2D, MaxPooling2D, Add, Dense, UpSampling2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# This code snippet forces tensorflow to not automatically allocate all GPU ram which can be an issue in notebook environment\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "tf.debugging.disable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a856cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# # Force Tensorflow to use my GPU\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c7c48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "We have applied the \n",
    "residual connection after two convolutional layer\n",
    "size of filters is 3*3, consistently maintained for whole network. \n",
    "\n",
    "**In the encoder part, the size of first residual block is 256 * 256, second and third blocks are of size 128 * 128 and 64 * 64**\n",
    "\n",
    "In decoder part\n",
    "the reverse way, starting with 64 * 64 residual block. \n",
    "\n",
    "**In between, the hourglass module is based on residual blocks along with skip\n",
    "connections, as can be seen in Fig. 2. The residual blocks are labeled\n",
    "as R1;R2;R3;R4;R5;R6;R7;R8;R9, each of which consists of\n",
    "three convolutional layers**\n",
    "\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "\n",
    "**The batch size is chosen to be 8**. \n",
    "\n",
    "**Resized the images to 256 * 256 for Ikea and\n",
    "128 * 128 for NYU V2 Depth dataset**\n",
    "\n",
    "However, our network is flexible to take input images as \n",
    "in square matrix (64 * 64; 128 * 128 : : : 512 * 512 . . . ) form\n",
    "\n",
    "\n",
    "----------------------------------------\n",
    "As our network does not involve any pre-trained weights, we\n",
    "first train the network using the MSE loss for some epochs. Following\n",
    "this, in our case, the ground-truth depth map and the estimated\n",
    "depth map, are passed through the network, and the loss is measured\n",
    "by using feature maps of the second last layer of encoder before the\n",
    "hourglass. This can also be called as a feature reconstruction loss\n",
    "between the predicted map and the ground truth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4add9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, strides=1):\n",
    "    y = Conv2D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
    "\n",
    "    # Adjust the shortcut connection to match the dimensions\n",
    "    shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
    "    y = Add()([y, shortcut])\n",
    "\n",
    "    y = Activation('relu')(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def hourglass_module(x, filters):\n",
    "    # First Residual Block\n",
    "    x_res1 = residual_block(x, filters)\n",
    "\n",
    "    # Downsampling\n",
    "    x_downsampled = MaxPooling2D((2, 2), padding='same')(x_res1)\n",
    "\n",
    "    # Second Residual Block\n",
    "    x_res2 = residual_block(x_downsampled, filters)\n",
    "\n",
    "    # Upsampling\n",
    "    x_upsampled = UpSampling2D((2, 2))(x_res2)\n",
    "\n",
    "    # Skip connection to the original input\n",
    "    x_skip = Conv2D(filters, (1, 1), padding='same')(x)\n",
    "\n",
    "    # Resize x_upsampled to match the shape of x_skip_resized\n",
    "    x_upsampled_resized = tf.image.resize(x_upsampled, size=tf.shape(x_skip)[1:3], method='nearest')\n",
    "\n",
    "    # Skip connection with the upsampled features\n",
    "    x = Add()([x_skip, x_upsampled_resized])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def create_models(dropout = False, dropout_rate = 0.2, model_name = 'base', input_shape =(256, 256, 3), filters = 8):\n",
    "    \n",
    "    # The input size is dependent on the dataset being used\n",
    "    input_shape == input_shape\n",
    "    \n",
    "    # Constantly maintain the filter size of 3x3 thought the whole model    \n",
    "    filter_size = (3,3)\n",
    "    \n",
    "    if model_name == 'base': # Base model as described in the research paper\n",
    "        \n",
    "        input_layer = keras.Input(input_shape, name = 'input_layer')\n",
    "        \n",
    "        if not dropout:\n",
    "            \n",
    "            # As the model requires intervention with the results, the values have to be stored\n",
    "            # Cannot simply be created using model.add(layers) - if wanted layerName.output would have to be used\n",
    "            \n",
    "            # -----Encoding CNN Block----- # \n",
    "            # The layers will be labeled as shown in the research paper\n",
    "            # There is a residual connection after every 2 convolution layers\n",
    "                \n",
    "            # Convolution block 1 \n",
    "            \n",
    "            # filters = # of filters, \n",
    "            # kernel_size = filter size - single value - assumes the filter is a square, \n",
    "            # padding = valid - no padding, same - padding evenly to the input, \n",
    "            # stride = how much does the filter move (assume 1 in this case)\n",
    "            # padding='same', activation = padding='same', activation function - need to test with relu and none\n",
    "            # use_bias = if True then it is used, we assume there is none, as there are no pretrained weights - can test with both\n",
    "            # First convolution layer\n",
    "            level_1_features=16\n",
    "            level_2_features=32\n",
    "            level_3_features=64\n",
    "\n",
    "            inputs = Input(shape=(256, 256, 3))\n",
    "\n",
    "            conv1 = Conv2D(level_1_features, (3, 3), padding='same', activation='relu')(inputs)\n",
    "\n",
    "            # Second convolution layer\n",
    "            conv2 = Conv2D(level_1_features, (3, 3), padding='same', activation='relu')(conv1)\n",
    "        #     conv2 = Activation('relu')(conv2)\n",
    "\n",
    "            # Third convolution layer\n",
    "            conv3 = Conv2D(level_1_features, (3, 3), padding='same', activation='relu')(conv2)\n",
    "        #     conv3 = Activation('relu')(conv3)\n",
    "            conv4Input = Add()([conv3, conv1])\n",
    "\n",
    "            # Fourth convolution layer with a residual connection\n",
    "            conv4 = Conv2D(level_2_features, (3, 3), padding='same', activation='relu')(conv4Input)\n",
    "        #     conv4 = Activation('relu')(conv4)\n",
    "            \n",
    "            #Max pooling after conv4\n",
    "            conv4_pooled = MaxPooling2D((2, 2))(conv4)\n",
    "\n",
    "            # fifth convolution layer \n",
    "            conv5 = Conv2D(level_2_features, (3, 3), padding='same', activation='relu')(conv4_pooled)\n",
    "        #     conv5 = Activation('relu')(conv5)\n",
    "            \n",
    "            # sixth convolution layer \n",
    "            conv6 = Conv2D(level_2_features, (3, 3), padding='same', activation='relu')(conv5)\n",
    "        #     conv6 = Activation('relu')(conv6)\n",
    "            \n",
    "            conv7Input = Add()([conv6, conv4_pooled])\n",
    "            \n",
    "            # seventh convolution layer with a residual connection\n",
    "            conv7 = Conv2D(level_3_features, (3, 3), padding='same', activation='relu')(conv7Input)\n",
    "        #     conv7 = Activation('relu')(conv7)\n",
    "            \n",
    "            #Max pooling after conv7\n",
    "            conv7_pooled = MaxPooling2D((2, 2), padding='same')(conv7)\n",
    "            \n",
    "            # eight convolution layer \n",
    "            conv8 = Conv2D(level_3_features, (3, 3), padding='same', activation='relu')(conv7_pooled)\n",
    "        #     conv8 = Activation('relu')(conv8)\n",
    "            \n",
    "            # nineth convolution layer \n",
    "            conv9 = Conv2D(level_3_features, (3, 3), padding='same', activation='relu')(conv8)\n",
    "        #     conv9 = Activation('relu')(conv9)\n",
    "            \n",
    "            conv10Input = Add()([conv9, conv7_pooled])\n",
    "            \n",
    "            #tenth convolutional layer with residual connection\n",
    "            conv10 = Conv2D(level_3_features, (3, 3), padding='same', activation='relu')(conv10Input)\n",
    "        #     conv10 = Activation('relu')(conv10)\n",
    "            \n",
    "            #max pooling after conv10\n",
    "            conv10_pooled = MaxPooling2D((2, 2), padding='same')(conv10)\n",
    "            \n",
    "            #This needs to fed into the Hour Glass\n",
    "            \n",
    "        #     hourGlass1Output = hourglass_module(conv10_pooled, 64)\n",
    "            # Stacked Hourglass\n",
    "            hourglass = conv10_pooled\n",
    "            for _ in range(4):  # You can adjust the number of stacked hourglass modules\n",
    "                hourglass = hourglass_module(hourglass, 128) \n",
    "                \n",
    "            for _ in range(4):  # You can adjust the number of stacked hourglass modules\n",
    "                hourglass = hourglass_module(hourglass, 128) \n",
    "                \n",
    "\n",
    "            dec_conv1 = UpSampling2D((2, 2))(hourglass)\n",
    "            \n",
    "            dec_conv2 = Conv2D(level_3_features, (3, 3), padding='same', activation='relu')(dec_conv1) # this output gets added to output of conv 4\n",
    "            \n",
    "            dec_conv3 = Conv2D(level_3_features, (3, 3), padding='same', activation='relu')(dec_conv2)\n",
    "            \n",
    "            dec_conv4 = Conv2D(level_3_features, (3, 3), padding='same', activation='relu')(dec_conv3)\n",
    "            \n",
    "            dec_conv5Input = Add()([dec_conv4, dec_conv2])\n",
    "            \n",
    "            dec_conv5 = Conv2D(level_2_features, (3, 3), padding='same', activation='relu')(dec_conv5Input)\n",
    "            dec_conv6 = UpSampling2D((2, 2))(dec_conv5) # add this to output of conv 8\n",
    "            \n",
    "            dec_conv7 = Conv2D(level_2_features, (3, 3), padding='same', activation='relu')(dec_conv6)\n",
    "            dec_conv8 = Conv2D(level_2_features, (3, 3), padding='same', activation='relu')(dec_conv7)\n",
    "            \n",
    "            dec_conv9Input = Add()([dec_conv8, dec_conv6])\n",
    "            \n",
    "            dec_conv9 = Conv2D(level_1_features, (3, 3), padding='same', activation='relu')(dec_conv9Input)\n",
    "            dec_conv10 = UpSampling2D((2, 2))(dec_conv9) # add this to output of conv 12\n",
    "\n",
    "            dec_conv11 = Conv2D(level_1_features, (3, 3), padding='same', activation='relu')(dec_conv10)\n",
    "            dec_conv12 = Conv2D(level_1_features, (3, 3), padding='same', activation='relu')(dec_conv11)\n",
    "            \n",
    "            dec_conv13Input = Add()([dec_conv12, dec_conv10])\n",
    "\n",
    "            dec_conv13 = Conv2D(256, (3, 3), padding='same', activation='relu')(dec_conv13Input)\n",
    "            \n",
    "            model = tf.keras.models.Model(inputs=input_layer, outputs=dec_conv13)\n",
    "            return model\n",
    "        \n",
    "        \n",
    "    if model_name == 'CNN-LSTM1': # Check if the location of the LSTM affects the models - before hourglass\n",
    "        if not dropout:\n",
    "\n",
    "            # As the model requires intervention with the results, the values have to be stored\n",
    "            # Cannot simply be created using model.add(layers) - if wanted layerName.output would have to be used\n",
    "            \n",
    "            # -----Encoding CNN Block----- # \n",
    "            # The layers will be labeled as shown in the research paper\n",
    "            # There is a residual connection after every 2 convolution layers\n",
    "                \n",
    "            # Convolution block 1 \n",
    "            \n",
    "            # filters = # of filters, \n",
    "            # kernel_size = filter size - single value - assumes the filter is a square, \n",
    "            # padding = valid - no padding, same - padding evenly to the input, \n",
    "            # stride = how much does the filter move (assume 1 in this case)\n",
    "            # padding='same', activation = padding='same', activation function - need to test with relu and none\n",
    "            # use_bias = if True then it is used, we assume there is none, as there are no pretrained weights - can test with both\n",
    "            conv1 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "            \n",
    "            # Convolution Block 2\n",
    "            conv2 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv1)\n",
    "            conv3 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
    "            \n",
    "            # Residual Connection from Conv1 output to Conv4 Input\n",
    "            # Add (Conv layer before input, output from the layer it is being connected to)\n",
    "            Residual1 = add([conv3, conv1])\n",
    "            \n",
    "            # Convolution Block 3\n",
    "            conv4 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual1)\n",
    "            # Using a 2D Max Pooling as the input is a 2D image\n",
    "            # Assume pooling size is 2,2 as default\n",
    "            pool1 = MaxPooling2D(2, padding = 'same')(conv4)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # Convolution Block 4\n",
    "            conv5 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(pool1)\n",
    "            conv6 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv5)\n",
    "            \n",
    "            # Residual Connection from Pool1 output to Conv7 input\n",
    "            Residual2 = add([conv6, pool1])\n",
    "            \n",
    "            # Convolution Block 5\n",
    "            conv7 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual2)\n",
    "            pool2 = MaxPooling2D(2, padding = 'same')(conv7)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            #Convolution Block 6\n",
    "            conv8 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(pool2)\n",
    "            conv9 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv8)\n",
    "            \n",
    "            # Residual Connection from Pool2 output to Conv10 input\n",
    "            Residual3 = add([conv9, pool2])\n",
    "            \n",
    "            # Convoluton Block 7\n",
    "            conv10 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual3)\n",
    "            pool3 = MaxPooling2D(2, padding = 'same')(conv10)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # The output will change accordingly to where the LSTM is being placed in other models\n",
    "            output = pool3\n",
    "            \n",
    "            \n",
    "            # ----- LSTM ----- #\n",
    "            lstm1 = keras.layers.Reshape((-1, filters))(output)\n",
    "            lstm1 = LSTM(units = filters, activation= 'relu', return_sequences=False)(lstm1)             \n",
    "            output = Reshape(target_shape=(256, 256, 3))(lstm1)\n",
    "            \n",
    "            \n",
    "            # -----Hourglass Encoder-Decoder----- #\n",
    "            \n",
    "            # Bottom up structure consists of convolution and max-pooling layers\n",
    "            # Up-Sampling and combination of features in Top-down manner\n",
    "            # Encoder\n",
    "            # 1st block - 256x256\n",
    "            # 2nd block - 128x128\n",
    "            # 3rd block - 64x64\n",
    "            \n",
    "            # Assuming middle sections are 32x32\n",
    "            \n",
    "            # Decoder\n",
    "            # 7th block - 64x64\n",
    "            # 8th block - 128x128\n",
    "            # 9th block - 256x256\n",
    "            \n",
    "            \n",
    "            # Bottom - up\n",
    "            # R1 Block\n",
    "            R1 = Conv2D(filters, kernel_size=256, padding='same')(output)\n",
    "            R1 = MaxPooling2D(2, padding='same')(R1)\n",
    "            \n",
    "            # R2 Block\n",
    "            R2 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R1)\n",
    "            R2 = MaxPooling2D(2, padding='same')(R2)\n",
    "            \n",
    "            # R3 Block\n",
    "            R3 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R2)\n",
    "            R3 = MaxPooling2D(2, padding='same')(R3)\n",
    "            \n",
    "            \n",
    "            # Middle\n",
    "            # R4 Block\n",
    "            R4 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R3)\n",
    "            R4 = MaxPooling2D(2, padding='same')(R4)\n",
    "            \n",
    "            \n",
    "            # R5 Block\n",
    "            R5 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R4)\n",
    "            R5 = MaxPooling2D(2, padding='same')(R5)\n",
    "            \n",
    "            \n",
    "            # R6 Block\n",
    "            R6 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R5)\n",
    "            R6 = MaxPooling2D(2, padding='same')(R6)\n",
    "            \n",
    "            Residual = add([R6, R3])\n",
    "            # Top- Down\n",
    "            # R7 Block\n",
    "            R7 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R7 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R7)\n",
    "            \n",
    "            # R8 Block\n",
    "            Residual = add([R7, R2])\n",
    "            R8 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R8 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R8)\n",
    "        \n",
    "            # R9 Block\n",
    "            \n",
    "            Residual = add([R8, R1])\n",
    "            R9 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R9 = Conv2D(filters, kernel_size=256, padding='same')(R9)\n",
    "            \n",
    "            output = R9\n",
    "        \n",
    "            # -----Hourglass Encode-Decoder----- #\n",
    "            \n",
    "            # Bottom - up\n",
    "            # R1 Block\n",
    "            R1 = Conv2D(filters, kernel_size=256, padding='same')(output)\n",
    "            R1 = MaxPooling2D(2, padding='same')(R1)\n",
    "            \n",
    "            # R2 Block\n",
    "            R2 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R1)\n",
    "            R2 = MaxPooling2D(2, padding='same')(R2)\n",
    "            \n",
    "            # R3 Block\n",
    "            R3 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R2)\n",
    "            R3 = MaxPooling2D(2, padding='same')(R3)\n",
    "            \n",
    "            \n",
    "            # Middle\n",
    "            # R4 Block\n",
    "            R4 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R3)\n",
    "            R4 = MaxPooling2D(2, padding='same')(R4)\n",
    "            \n",
    "            \n",
    "            # R5 Block\n",
    "            R5 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R4)\n",
    "            R5 = MaxPooling2D(2, padding='same')(R5)\n",
    "            \n",
    "            \n",
    "            # R6 Block\n",
    "            R6 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R5)\n",
    "            R6 = MaxPooling2D(2, padding='same')(R6)\n",
    "            \n",
    "            Residual = add([R6, R3])\n",
    "            # Top- Down\n",
    "            # R7 Block\n",
    "            R7 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R7 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R7)\n",
    "            \n",
    "            # R8 Block\n",
    "            Residual = add([R7, R2])\n",
    "            R8 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R8 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R8)\n",
    "        \n",
    "            # R9 Block\n",
    "            \n",
    "            Residual = add([R8, R1])\n",
    "            R9 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R9 = Conv2D(filters, kernel_size=256, padding='same')(R9)\n",
    "            \n",
    "            output = R9\n",
    "            \n",
    "            # -----Decoding CNN Block----- #\n",
    "            upconv1 = UpSampling2D(filter, kernel_size = 256, padding = 'same')(output)\n",
    "            conv2 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv1)\n",
    "            \n",
    "            # Convolution Block 2\n",
    "            conv3 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
    "            conv4 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv3)\n",
    "            \n",
    "            # Residual Connection from Conv1 output to Conv4 Input\n",
    "            # Add (Conv layer before input, output from the layer it is being connected to)\n",
    "            Residual1 = add([conv2, conv4])\n",
    "            \n",
    "            # Convolution Block 3\n",
    "            conv5 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual1)\n",
    "            upconv6 = UpSampling2D(2, padding = 'same')(conv5)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # Convolution Block 4\n",
    "            conv7 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv6)\n",
    "            conv8 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv7)\n",
    "            \n",
    "            # Residual Connection from Pool1 output to Conv7 input\n",
    "            Residual2 = add([upconv6, conv8])\n",
    "            \n",
    "            # Convolution Block 5\n",
    "            conv9 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual2)\n",
    "            upconv10 = UpSampling2D(2, interpolation='nearest')(conv9)\n",
    "            \n",
    "            # Convoluton Block 7\n",
    "            conv11 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv10)\n",
    "            conv12 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv12)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            \n",
    "            # Residual Connection from Pool2 output to Conv10 input\n",
    "            Residual3 = add([conv10, conv12])\n",
    "            \n",
    "            # Convolution Block 8\n",
    "            conv13 = Conv2D(filters, kernel_size=3, padding='same', activation = 'relu')(Residual3)\n",
    "            \n",
    "            \n",
    "            output_layer = conv13  # Adjust the number of units for your specific task\n",
    "\n",
    "            model = Model(input_layer, output_layer, name = 'LSTM before Hourglass')\n",
    "\n",
    "            return model\n",
    "            \n",
    "    if model_name == 'CNN-LSTM2': # Check if the location of the LSTM affects the models - after the hourglass\n",
    "        if not dropout:\n",
    "            \n",
    "            # As the model requires intervention with the results, the values have to be stored\n",
    "            # Cannot simply be created using model.add(layers) - if wanted layerName.output would have to be used\n",
    "            \n",
    "            # -----Encoding CNN Block----- # \n",
    "            # The layers will be labeled as shown in the research paper\n",
    "            # There is a residual connection after every 2 convolution layers\n",
    "                \n",
    "            # Convolution block 1 \n",
    "            \n",
    "            # filters = # of filters, \n",
    "            # kernel_size = filter size - single value - assumes the filter is a square, \n",
    "            # padding = valid - no padding, same - padding evenly to the input, \n",
    "            # stride = how much does the filter move (assume 1 in this case)\n",
    "            # padding='same', activation = padding='same', activation function - need to test with relu and none\n",
    "            # use_bias = if True then it is used, we assume there is none, as there are no pretrained weights - can test with both\n",
    "            conv1 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "            \n",
    "            # Convolution Block 2\n",
    "            conv2 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv1)\n",
    "            conv3 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
    "            \n",
    "            # Residual Connection from Conv1 output to Conv4 Input\n",
    "            # Add (Conv layer before input, output from the layer it is being connected to)\n",
    "            Residual1 = add([conv3, conv1])\n",
    "            \n",
    "            # Convolution Block 3\n",
    "            conv4 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual1)\n",
    "            # Using a 2D Max Pooling as the input is a 2D image\n",
    "            # Assume pooling size is 2,2 as default\n",
    "            pool1 = MaxPooling2D(2, padding = 'same')(conv4)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # Convolution Block 4\n",
    "            conv5 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(pool1)\n",
    "            conv6 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv5)\n",
    "            \n",
    "            # Residual Connection from Pool1 output to Conv7 input\n",
    "            Residual2 = add([conv6, pool1])\n",
    "            \n",
    "            # Convolution Block 5\n",
    "            conv7 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual2)\n",
    "            pool2 = MaxPooling2D(2, padding = 'same')(conv7)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            #Convolution Block 6\n",
    "            conv8 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(pool2)\n",
    "            conv9 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv8)\n",
    "            \n",
    "            # Residual Connection from Pool2 output to Conv10 input\n",
    "            Residual3 = add([conv9, pool2])\n",
    "            \n",
    "            # Convoluton Block 7\n",
    "            conv10 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual3)\n",
    "            pool3 = MaxPooling2D(2, padding = 'same')(conv10)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # The output will change accordingly to where the LSTM is being placed in other models\n",
    "            output = pool3\n",
    "            \n",
    "            # -----Hourglass Encoder-Decoder----- #\n",
    "            \n",
    "            # Bottom up structure consists of convolution and max-pooling layers\n",
    "            # Up-Sampling and combination of features in Top-down manner\n",
    "            # Encoder\n",
    "            # 1st block - 256x256\n",
    "            # 2nd block - 128x128\n",
    "            # 3rd block - 64x64\n",
    "            \n",
    "            # Assuming middle sections are 32x32\n",
    "            \n",
    "            # Decoder\n",
    "            # 7th block - 64x64\n",
    "            # 8th block - 128x128\n",
    "            # 9th block - 256x256\n",
    "            \n",
    "            # Bottom - up\n",
    "            # R1 Block\n",
    "            R1 = Conv2D(filters, kernel_size=256, padding='same')(output)\n",
    "            R1 = MaxPooling2D(2, padding='same')(R1)\n",
    "            \n",
    "            # R2 Block\n",
    "            R2 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R1)\n",
    "            R2 = MaxPooling2D(2, padding='same')(R2)\n",
    "            \n",
    "            # R3 Block\n",
    "            R3 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R2)\n",
    "            R3 = MaxPooling2D(2, padding='same')(R3)\n",
    "            \n",
    "            \n",
    "            # Middle\n",
    "            # R4 Block\n",
    "            R4 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R3)\n",
    "            R4 = MaxPooling2D(2, padding='same')(R4)\n",
    "            \n",
    "            \n",
    "            # R5 Block\n",
    "            R5 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R4)\n",
    "            R5 = MaxPooling2D(2, padding='same')(R5)\n",
    "            \n",
    "            \n",
    "            # R6 Block\n",
    "            R6 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R5)\n",
    "            R6 = MaxPooling2D(2, padding='same')(R6)\n",
    "            \n",
    "            Residual = add([R6, R3])\n",
    "            # Top- Down\n",
    "            # R7 Block\n",
    "            R7 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R7 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R7)\n",
    "            \n",
    "            # R8 Block\n",
    "            Residual = add([R7, R2])\n",
    "            R8 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R8 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R8)\n",
    "        \n",
    "            # R9 Block\n",
    "            \n",
    "            Residual = add([R8, R1])\n",
    "            R9 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R9 = Conv2D(filters, kernel_size=256, padding='same')(R9)\n",
    "            \n",
    "            output = R9\n",
    "        \n",
    "            # -----Hourglass Encode-Decoder----- #\n",
    "            \n",
    "            # Bottom - up\n",
    "            # R1 Block\n",
    "            R1 = Conv2D(filters, kernel_size=256, padding='same')(output)\n",
    "            R1 = MaxPooling2D(2, padding='same')(R1)\n",
    "            \n",
    "            # R2 Block\n",
    "            R2 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R1)\n",
    "            R2 = MaxPooling2D(2, padding='same')(R2)\n",
    "            \n",
    "            # R3 Block\n",
    "            R3 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R2)\n",
    "            R3 = MaxPooling2D(2, padding='same')(R3)\n",
    "            \n",
    "            \n",
    "            # Middle\n",
    "            # R4 Block\n",
    "            R4 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R3)\n",
    "            R4 = MaxPooling2D(2, padding='same')(R4)\n",
    "            \n",
    "            \n",
    "            # R5 Block\n",
    "            R5 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R4)\n",
    "            R5 = MaxPooling2D(2, padding='same')(R5)\n",
    "            \n",
    "            \n",
    "            # R6 Block\n",
    "            R6 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R5)\n",
    "            R6 = MaxPooling2D(2, padding='same')(R6)\n",
    "            \n",
    "            Residual = add([R6, R3])\n",
    "            # Top- Down\n",
    "            # R7 Block\n",
    "            R7 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R7 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R7)\n",
    "            \n",
    "            # R8 Block\n",
    "            Residual = add([R7, R2])\n",
    "            R8 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R8 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R8)\n",
    "        \n",
    "            # R9 Block\n",
    "            \n",
    "            Residual = add([R8, R1])\n",
    "            R9 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R9 = Conv2D(filters, kernel_size=256, padding='same')(R9)\n",
    "            \n",
    "            output = R9\n",
    "            \n",
    "            \n",
    "            # ----- LSTM ----- #\n",
    "            lstm1 = keras.layers.Reshape((-1, filters))(output)\n",
    "            lstm1 = LSTM(units = filters, activation= 'relu', return_sequences=False)(lstm1)             \n",
    "            output = Reshape(target_shape=(256, 256, 3))(lstm1)\n",
    "            \n",
    "            \n",
    "            # -----Decoding CNN Block----- #\n",
    "            upconv1 = UpSampling2D(filter, kernel_size = 256, padding = 'same')(output)\n",
    "            conv2 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv1)\n",
    "            \n",
    "            # Convolution Block 2\n",
    "            conv3 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
    "            conv4 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv3)\n",
    "            \n",
    "            # Residual Connection from Conv1 output to Conv4 Input\n",
    "            # Add (Conv layer before input, output from the layer it is being connected to)\n",
    "            Residual1 = add([conv2, conv4])\n",
    "            \n",
    "            # Convolution Block 3\n",
    "            conv5 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual1)\n",
    "            upconv6 = UpSampling2D(2, padding = 'same')(conv5)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # Convolution Block 4\n",
    "            conv7 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv6)\n",
    "            conv8 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv7)\n",
    "            \n",
    "            # Residual Connection from Pool1 output to Conv7 input\n",
    "            Residual2 = add([upconv6, conv8])\n",
    "            \n",
    "            # Convolution Block 5\n",
    "            conv9 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual2)\n",
    "            upconv10 = UpSampling2D(2, interpolation='nearest')(conv9)\n",
    "            \n",
    "            # Convoluton Block 7\n",
    "            conv11 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv10)\n",
    "            conv12 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv12)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            \n",
    "            # Residual Connection from Pool2 output to Conv10 input\n",
    "            Residual3 = add([conv10, conv12])\n",
    "            \n",
    "            # Convolution Block 8\n",
    "            conv13 = Conv2D(filters, kernel_size=3, padding='same', activation = 'relu')(Residual3)\n",
    "            \n",
    "            \n",
    "            output_layer = conv13  # Adjust the number of units for your specific task\n",
    "\n",
    "            model = Model(input_layer, output_layer, name = 'LSTM after Hourglass')\n",
    "\n",
    "            return model\n",
    "            \n",
    "    if model_name == 'CNN-2LSTM': # model which will have the LSTM before and after the hourglass\n",
    "        if not dropout:\n",
    "            \n",
    "            # As the model requires intervention with the results, the values have to be stored\n",
    "            # Cannot simply be created using model.add(layers) - if wanted layerName.output would have to be used\n",
    "            \n",
    "            # -----Encoding CNN Block----- # \n",
    "            # The layers will be labeled as shown in the research paper\n",
    "            # There is a residual connection after every 2 convolution layers\n",
    "                \n",
    "            # Convolution block 1 \n",
    "            \n",
    "            # filters = # of filters, \n",
    "            # kernel_size = filter size - single value - assumes the filter is a square, \n",
    "            # padding = valid - no padding, same - padding evenly to the input, \n",
    "            # stride = how much does the filter move (assume 1 in this case)\n",
    "            # padding='same', activation = padding='same', activation function - need to test with relu and none\n",
    "            # use_bias = if True then it is used, we assume there is none, as there are no pretrained weights - can test with both\n",
    "            conv1 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "            \n",
    "            # Convolution Block 2\n",
    "            conv2 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv1)\n",
    "            conv3 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
    "            \n",
    "            # Residual Connection from Conv1 output to Conv4 Input\n",
    "            # Add (Conv layer before input, output from the layer it is being connected to)\n",
    "            Residual1 = add([conv3, conv1])\n",
    "            \n",
    "            # Convolution Block 3\n",
    "            conv4 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual1)\n",
    "            # Using a 2D Max Pooling as the input is a 2D image\n",
    "            # Assume pooling size is 2,2 as default\n",
    "            pool1 = MaxPooling2D(2, padding = 'same')(conv4)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # Convolution Block 4\n",
    "            conv5 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(pool1)\n",
    "            conv6 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv5)\n",
    "            \n",
    "            # Residual Connection from Pool1 output to Conv7 input\n",
    "            Residual2 = add([conv6, pool1])\n",
    "            \n",
    "            # Convolution Block 5\n",
    "            conv7 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual2)\n",
    "            pool2 = MaxPooling2D(2, padding = 'same')(conv7)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            #Convolution Block 6\n",
    "            conv8 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(pool2)\n",
    "            conv9 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv8)\n",
    "            \n",
    "            # Residual Connection from Pool2 output to Conv10 input\n",
    "            Residual3 = add([conv9, pool2])\n",
    "            \n",
    "            # Convoluton Block 7\n",
    "            conv10 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual3)\n",
    "            pool3 = MaxPooling2D(2, padding = 'same')(conv10)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # The output will change accordingly to where the LSTM is being placed in other models\n",
    "            output = pool3\n",
    "            \n",
    "            \n",
    "            \n",
    "            # ----- LSTM ----- #\n",
    "            lstm1 = keras.layers.Reshape((-1, filters))(output)\n",
    "            lstm1_output = LSTM(units = filters, activation= 'relu', return_sequences=False)(lstm1)\n",
    "            output = Reshape(target_shape=(256, 256, 3))(lstm1_output)\n",
    "            \n",
    "\n",
    "            # -----Hourglass Encoder-Decoder----- #\n",
    "            \n",
    "            # Bottom up structure consists of convolution and max-pooling layers\n",
    "            # Up-Sampling and combination of features in Top-down manner\n",
    "            # Encoder\n",
    "            # 1st block - 256x256\n",
    "            # 2nd block - 128x128\n",
    "            # 3rd block - 64x64\n",
    "            \n",
    "            # Assuming middle sections are 32x32\n",
    "            \n",
    "            # Decoder\n",
    "            # 7th block - 64x64\n",
    "            # 8th block - 128x128\n",
    "            # 9th block - 256x256\n",
    "                        \n",
    "            # Bottom - up\n",
    "            # R1 Block\n",
    "            R1 = Conv2D(filters, kernel_size=256, padding='same')(output)\n",
    "            R1 = MaxPooling2D(2, padding='same')(R1)\n",
    "            \n",
    "            # R2 Block\n",
    "            R2 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R1)\n",
    "            R2 = MaxPooling2D(2, padding='same')(R2)\n",
    "            \n",
    "            # R3 Block\n",
    "            R3 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R2)\n",
    "            R3 = MaxPooling2D(2, padding='same')(R3)\n",
    "            \n",
    "            \n",
    "            # Middle\n",
    "            # R4 Block\n",
    "            R4 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R3)\n",
    "            R4 = MaxPooling2D(2, padding='same')(R4)\n",
    "            \n",
    "            \n",
    "            # R5 Block\n",
    "            R5 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R4)\n",
    "            R5 = MaxPooling2D(2, padding='same')(R5)\n",
    "            \n",
    "            \n",
    "            # R6 Block\n",
    "            R6 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R5)\n",
    "            R6 = MaxPooling2D(2, padding='same')(R6)\n",
    "            \n",
    "            Residual = add([R6, R3])\n",
    "            # Top- Down\n",
    "            # R7 Block\n",
    "            R7 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R7 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R7)\n",
    "            \n",
    "            # R8 Block\n",
    "            Residual = add([R7, R2])\n",
    "            R8 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R8 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R8)\n",
    "        \n",
    "            # R9 Block\n",
    "            \n",
    "            Residual = add([R8, R1])\n",
    "            R9 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R9 = Conv2D(filters, kernel_size=256, padding='same')(R9)\n",
    "            \n",
    "            output = R9\n",
    "        \n",
    "            # -----Hourglass Encode-Decoder----- #\n",
    "            \n",
    "            # Bottom - up\n",
    "            # R1 Block\n",
    "            R1 = Conv2D(filters, kernel_size=256, padding='same')(output)\n",
    "            R1 = MaxPooling2D(2, padding='same')(R1)\n",
    "            \n",
    "            # R2 Block\n",
    "            R2 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R1)\n",
    "            R2 = MaxPooling2D(2, padding='same')(R2)\n",
    "            \n",
    "            # R3 Block\n",
    "            R3 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R2)\n",
    "            R3 = MaxPooling2D(2, padding='same')(R3)\n",
    "            \n",
    "            \n",
    "            # Middle\n",
    "            # R4 Block\n",
    "            R4 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R3)\n",
    "            R4 = MaxPooling2D(2, padding='same')(R4)\n",
    "            \n",
    "            \n",
    "            # R5 Block\n",
    "            R5 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R4)\n",
    "            R5 = MaxPooling2D(2, padding='same')(R5)\n",
    "            \n",
    "            \n",
    "            # R6 Block\n",
    "            R6 = Conv2D(filters, kernel_size=32, padding='same', activation='relu')(R5)\n",
    "            R6 = MaxPooling2D(2, padding='same')(R6)\n",
    "            \n",
    "            Residual = add([R6, R3])\n",
    "            # Top- Down\n",
    "            # R7 Block\n",
    "            R7 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R7 = Conv2D(filters, kernel_size=64, padding='same', activation='relu')(R7)\n",
    "            \n",
    "            # R8 Block\n",
    "            Residual = add([R7, R2])\n",
    "            R8 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R8 = Conv2D(filters, kernel_size=128, padding='same', activation='relu' )(R8)\n",
    "        \n",
    "            # R9 Block\n",
    "            \n",
    "            Residual = add([R8, R1])\n",
    "            R9 = UpSampling2D(2, interpolation='nearest')(Residual)\n",
    "            R9 = Conv2D(filters, kernel_size=256, padding='same')(R9)\n",
    "            \n",
    "            output = R9\n",
    "            \n",
    "            # ----- LSTM ----- #\n",
    "            lstm1 = keras.layers.Reshape((-1, filters))(output)\n",
    "            lstm1_output = LSTM(units = filters, activation= 'relu', return_sequences=False)(lstm1)\n",
    "            output = Reshape(target_shape=(256, 256, 3))(lstm1_output)\n",
    "       \n",
    "            \n",
    "            # -----Decoding CNN Block----- #\n",
    "            upconv1 = UpSampling2D(filter, kernel_size = 256, padding = 'same')(output)\n",
    "            conv2 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv1)\n",
    "            \n",
    "            # Convolution Block 2\n",
    "            conv3 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv2)\n",
    "            conv4 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv3)\n",
    "            \n",
    "            # Residual Connection from Conv1 output to Conv4 Input\n",
    "            # Add (Conv layer before input, output from the layer it is being connected to)\n",
    "            Residual1 = add([conv2, conv4])\n",
    "            \n",
    "            # Convolution Block 3\n",
    "            conv5 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual1)\n",
    "            upconv6 = UpSampling2D(2, padding = 'same')(conv5)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            # Convolution Block 4\n",
    "            conv7 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv6)\n",
    "            conv8 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv7)\n",
    "            \n",
    "            # Residual Connection from Pool1 output to Conv7 input\n",
    "            Residual2 = add([upconv6, conv8])\n",
    "            \n",
    "            # Convolution Block 5\n",
    "            conv9 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Residual2)\n",
    "            upconv10 = UpSampling2D(2, interpolation='nearest')(conv9)\n",
    "            \n",
    "            # Convoluton Block 7\n",
    "            conv11 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(upconv10)\n",
    "            conv12 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(conv12)\n",
    "            #filters = filters*2\n",
    "            \n",
    "            \n",
    "            # Residual Connection from Pool2 output to Conv10 input\n",
    "            Residual3 = add([conv10, conv12])\n",
    "            \n",
    "            # Convolution Block 8\n",
    "            conv13 = Conv2D(filters, kernel_size=3, padding='same', activation = 'relu')(Residual3)\n",
    "            \n",
    "            \n",
    "            output_layer = conv13  # Adjust the number of units for your specific task\n",
    "\n",
    "            model = Model(input_layer, output_layer, name = 'CNN Double LSTM')\n",
    "\n",
    "            return model\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9aded0",
   "metadata": {},
   "source": [
    "As our network does not involve any pre-trained weights, we\n",
    "first train the network using the MSE loss for some epochs. Following\n",
    "this, in our case, the ground-truth depth map and the estimated\n",
    "depth map, are passed through the network, and the loss is measured\n",
    "by using feature maps of the second last layer of encoder before the\n",
    "hourglass. This can also be called as a feature reconstruction loss\n",
    "between the predicted map and the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c076486",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1989457122.py, line 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 100\u001b[1;36m\u001b[0m\n\u001b[1;33m    'CNN_LSTM1': CNN_LSTM1\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def train_models(x, y, x_test = None, y_test = None, epochs = 250, batch_size = 8):\n",
    "\n",
    "    if x_test is None or y_test is None:\n",
    "        # Split data into training and testing using the dataset provided\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    else:\n",
    "        X_train, y_train = X, y\n",
    "       \n",
    "    # Image segmentation metric - https://keras.io/api/metrics/segmentation_metrics/#meaniou-class\n",
    "    \n",
    "    # ----------------------Building the base model---------------------------\n",
    "    base = create_models(dropout = False, dropout_rate = 0.2, model_name = 'base', input_shape =(256, 256, 3), filters = 64)\n",
    "    base.compile(optimizer = 'adam', loss = keras.losses.MeanSquaredError, metrics = [keras.metrics.MeanIoU] )\n",
    "    image_path = 'base_model.png'\n",
    "    keras.utils.plot_model(baseModel, to_file=dot_image_file, show_shapes=True)\n",
    "    \n",
    "    # ----------------------Building the CRNN - 1 LSTM Before model---------------------------\n",
    "    CNN_LSTM1 = create_models(dropout = False, dropout_rate = 0.2, model_name = 'CNN-LSTM1', input_shape =(256, 256, 3), filters = 64)\n",
    "    CNN_LSTM1.compile(optimizer = 'adam', loss = keras.losses.MeanSquaredError, metrics = [keras.metrics.MeanIoU] )\n",
    "    image_path = 'Before_hourglass_model.png'\n",
    "    keras.utils.plot_model(baseModel, to_file=dot_image_file, show_shapes=True)\n",
    "    \n",
    "    \n",
    "    # ----------------------Building the CRNN - 1 LSTM After model---------------------------\n",
    "    CNN_LSTM2 = create_models(dropout = False, dropout_rate = 0.2, model_name = 'CNN-LSTM2', input_shape =(256, 256, 3), filters = 64)\n",
    "    CNN_LSTM2.compile(optimizer = 'adam', loss = keras.losses.MeanSquaredError, metrics = [keras.metrics.MeanIoU] )\n",
    "    image_path = 'After_hourglass_model.png'\n",
    "    keras.utils.plot_model(baseModel, to_file=dot_image_file, show_shapes=True)\n",
    "    \n",
    "    \n",
    "    # ----------------------Building the CRNN - 2 LSTMs model---------------------------\n",
    "    CNN_2LSTM = create_models(dropout = False, dropout_rate = 0.2, model_name = 'CNN-2LSTM', input_shape =(256, 256, 3), filters = 64)\n",
    "    CNN_2LSTM.compile(optimizer = 'adam', loss = keras.losses.MeanSquaredError, metrics = [keras.metrics.MeanIoU] )\n",
    "    image_path = '2_LSTM_model.png'\n",
    "    keras.utils.plot_model(baseModel, to_file=dot_image_file, show_shapes=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"----------------------Training the Base Model...----------------------\")\n",
    "    path = 'base_AIR.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='loss',\n",
    "                                                                mode='min',\n",
    "                                                                save_best_only=True)\n",
    "    \n",
    "    base_history = base.fit(x, y,\n",
    "                            epochs=epochs, \n",
    "                            batch_size=batch_size,\n",
    "                            # Can check for validation loss and use that as the metric\n",
    "                            callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n----------------------Training the CNN_LSTM1 Model...----------------------\")\n",
    "    path = 'CNN_LSTM1.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='loss',\n",
    "                                                                mode='min',\n",
    "                                                                save_best_only=True)\n",
    "    \n",
    "    CNN_LSTM1_history = CNN_LSTM1.fit(x, y,\n",
    "                            epochs=epochs, \n",
    "                            batch_size=batch_size,\n",
    "                            # Can check for validation loss and use that as the metric\n",
    "                            callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n----------------------Training the CNN_LSTM2 Model...----------------------\")\n",
    "    path = 'CNN_LSTM2.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='loss',\n",
    "                                                                mode='min',\n",
    "                                                                save_best_only=True)\n",
    "    \n",
    "    CNN_LSTM2_history = CNN_LSTM2.fit(x, y,\n",
    "                            epochs=epochs, \n",
    "                            batch_size=batch_size,\n",
    "                            # Can check for validation loss and use that as the metric\n",
    "                            callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\n----------------------Training the CNN_2LSTM Model...----------------------\")\n",
    "    path = 'CNN_2LSTM.tf'\n",
    "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                                save_weights_only=True,\n",
    "                                                                monitor='loss',\n",
    "                                                                mode='min',\n",
    "                                                                save_best_only=True)\n",
    "    \n",
    "    CNN_2LSTM_history = CNN_2LSTM.fit(x, y,\n",
    "                            epochs=epochs, \n",
    "                            batch_size=batch_size,\n",
    "                            # Can check for validation loss and use that as the metric\n",
    "                            callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    model = {\n",
    "        'Base': base\n",
    "        'CNN_LSTM1': CNN_LSTM1\n",
    "        'CNN_LSTM2': CNN_LSTM2\n",
    "        'CNN_2LSTM': CNN_2LSTM\n",
    "        \n",
    "    }\n",
    "    \n",
    "    history = {\n",
    "        'Base': base_history\n",
    "        'CNN_LSTM1': CNN_LSTM1_history\n",
    "        'CNN_LSTM2': CNN_LSTM2_history\n",
    "        'CNN_2LSTM': CNN_2LSTM_history\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# dataFolder = \"C:\\\\Users\\\\Aidan\\\\Desktop\\\\Code\\\\AI Robotics\\\\Project\\\\data\"\n",
    "dataFolder = \"C:\\\\Users\\\\ariel\\\\OneDrive - Kennesaw State University\\\\Graduate School\\\\Fall 2023\\\\CS 7050 - AI and Robotics\\\\Group Project\\\\GroupProject - GitRepo\\\\nyu_data\\\\data\"\n",
    "inputImageSize = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "data_loading_percentage = 20\n",
    "trainTestSplit = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSequences = glob.glob(dataFolder + \"\\\\nyu2_train\\\\*\")\n",
    "\n",
    "validIndices = []\n",
    "imageCount = 0\n",
    "\n",
    "for imageSequence in imageSequences[0:int(len(imageSequences)*(data_loading_percentage/100))]:\n",
    "    inputImages = glob.glob(imageSequence + \"\\\\*.jpg\")\n",
    "    [validIndices.append(imageCount+j) for j in range(2, len(inputImages))]\n",
    "    imageCount += len(inputImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortImages(inputList):\n",
    "    return [x for _, x in sorted(zip([int(input[input.rfind(\"\\\\\") + 1:-4]) for input in inputList], inputList))]\n",
    "\n",
    "def print_progress_bar(iteration, total, prefix='', suffix='', length=25, fill=''):\n",
    "    percent = (\"{0:.1f}\").format(100 * (iteration / float(total)))\n",
    "    filled_length = int(length * iteration // total)\n",
    "    bar = fill * filled_length + '-' * (length - filled_length)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end='\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total-1: \n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "imageData = np.empty((imageCount, inputImageSize[0], inputImageSize[1], 3), dtype='int16')\n",
    "depthData = np.empty((imageCount, inputImageSize[0], inputImageSize[1]), dtype='int16')\n",
    "\n",
    "\n",
    "imageSequences = glob.glob(dataFolder + \"\\\\nyu2_train\\\\*\")\n",
    "index = 0\n",
    "\n",
    "for i, imageSequence in enumerate(imageSequences[0:int(len(imageSequences)*(data_loading_percentage/100))]):\n",
    "    inputImages = sortImages(glob.glob(imageSequence + \"\\\\*.jpg\"))\n",
    "    depthImages = sortImages(glob.glob(imageSequence + \"\\\\*.png\"))\n",
    "\n",
    "    imageData[index:index+len(inputImages)] = [np.asarray(Image.open(file).resize(inputImageSize), dtype='int16') for file in inputImages]\n",
    "    depthData[index:index+len(depthImages)] = [np.asarray(Image.open(file).resize(inputImageSize), dtype='int16') for file in depthImages]\n",
    "\n",
    "    index += len(inputImages)\n",
    "\n",
    "    print_progress_bar(i, len(imageSequences[0:int(len(imageSequences)*(data_loading_percentage/100))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, labels, validIndices, batch_size):\n",
    "    while True:\n",
    "        selectedIndices = np.random.choice(validIndices, batch_size)\n",
    "        batch_data = np.asarray([np.asarray(data[index-2:index+1]) for index in selectedIndices])\n",
    "        batch_labels = np.asarray([np.asarray(labels[index]) for index in selectedIndices])\n",
    "        yield batch_data, batch_labels\n",
    "\n",
    "data_generator(imageData, depthData, validIndices, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f0a03b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Aidan\\Desktop\\Code\\AI Robotics\\Project\\CS7050_AI_Robotics_GroupProject\\AI_Robotics_Final_Project_Model_Testing.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model, history \u001b[39m=\u001b[39m train_models(x, y, x_test \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, y_test \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, epochs \u001b[39m=\u001b[39m \u001b[39m250\u001b[39m, batch_size \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_models' is not defined"
     ]
    }
   ],
   "source": [
    "model, history = train_models(x, y, x_test = None, y_test = None, epochs = 250, batch_size = 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f94d05c",
   "metadata": {},
   "source": [
    "## Can be used to produce high detail images of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0175d081",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\") at layer \"conv2d_350\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Aidan\\Desktop\\Code\\AI Robotics\\Project\\CS7050_AI_Robotics_GroupProject\\AI_Robotics_Final_Project_Model_Testing.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m baseModel \u001b[39m=\u001b[39m create_models(dropout \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, dropout_rate \u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m, model_name \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mbase\u001b[39;49m\u001b[39m'\u001b[39;49m, input_shape \u001b[39m=\u001b[39;49m(\u001b[39m256\u001b[39;49m, \u001b[39m256\u001b[39;49m, \u001b[39m3\u001b[39;49m), filters \u001b[39m=\u001b[39;49m \u001b[39m8\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# dot_image_file = 'base_model.png'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# keras.utils.plot_model(baseModel, to_file=dot_image_file, show_shapes=True)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Aidan\\Desktop\\Code\\AI Robotics\\Project\\CS7050_AI_Robotics_GroupProject\\AI_Robotics_Final_Project_Model_Testing.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X14sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m         dec_conv13Input \u001b[39m=\u001b[39m Add()([dec_conv12, dec_conv10])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X14sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m         dec_conv13 \u001b[39m=\u001b[39m Conv2D(\u001b[39m256\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(dec_conv13Input)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X14sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m         model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mModel(inputs\u001b[39m=\u001b[39;49minput_layer, outputs\u001b[39m=\u001b[39;49mdec_conv13)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X14sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Aidan/Desktop/Code/AI%20Robotics/Project/CS7050_AI_Robotics_GroupProject/AI_Robotics_Final_Project_Model_Testing.ipynb#X14sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCNN-LSTM1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m# Check if the location of the LSTM affects the models - before hourglass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aidan\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aidan\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:165\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m    157\u001b[0m         [\n\u001b[0;32m    158\u001b[0m             functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    159\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[0;32m    160\u001b[0m         ]\n\u001b[0;32m    161\u001b[0m     ):\n\u001b[0;32m    162\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    163\u001b[0m             inputs, outputs\n\u001b[0;32m    164\u001b[0m         )\n\u001b[1;32m--> 165\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Aidan\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aidan\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:264\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_coordinates\u001b[39m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[0;32m    263\u001b[0m \u001b[39m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[39m=\u001b[39m _map_graph_network(\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs\n\u001b[0;32m    266\u001b[0m )\n\u001b[0;32m    267\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_nodes \u001b[39m=\u001b[39m nodes\n\u001b[0;32m    268\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes_by_depth \u001b[39m=\u001b[39m nodes_by_depth\n",
      "File \u001b[1;32mc:\\Users\\Aidan\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:1128\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(node\u001b[39m.\u001b[39mkeras_inputs):\n\u001b[0;32m   1127\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(x) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m computable_tensors:\n\u001b[1;32m-> 1128\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1129\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGraph disconnected: cannot obtain value for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1130\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensor \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m at layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1131\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe following previous layers were accessed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1132\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwithout issue: \u001b[39m\u001b[39m{\u001b[39;00mlayers_with_complete_input\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1133\u001b[0m         )\n\u001b[0;32m   1134\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(node\u001b[39m.\u001b[39moutputs):\n\u001b[0;32m   1135\u001b[0m     computable_tensors\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(x))\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\") at layer \"conv2d_350\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "baseModel = create_models(dropout = False, dropout_rate = 0.2, model_name = 'base', input_shape =(256, 256, 3), filters = 8)\n",
    "\n",
    "# dot_image_file = 'base_model.png'\n",
    "# keras.utils.plot_model(baseModel, to_file=dot_image_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe077492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efbd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
